{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#открываем train, заполняем пустоты нулями (это оказалось лучшей стратегией)\n",
    "train = pd.read_csv('train2.csv', encoding='latin-1', parse_dates=['Date', 'OrderDate'])\n",
    "train = train.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#открываем test полный, также заполняем пустоты нулями\n",
    "test_all = pd.read_csv('test2_old.csv', encoding='latin-1', parse_dates=['Date', 'OrderDate'])\n",
    "test_all = test_all.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#для последующих итерационных отладок\n",
    "train_save = train\n",
    "test_all_save = test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "#для последующих итерационных отладок\n",
    "train = train_save\n",
    "test = test_all_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dop1 = train.groupby(by=['OrderID', 'GroupID'])['OrderCnt'].agg([\"sum\"]).unstack(level=-1).reset_index().fillna(0)\n",
    "#train_dop2 = train.groupby(by=['OrderID', 'GroupID'])['ConfCnt'].agg([\"sum\"]).unstack(level=-1).reset_index().fillna(0)\n",
    "train_dop3 = train.groupby(by=['OrderID'])['OrderCnt'].agg([\"sum\"]).reset_index()\n",
    "train_dop4 = train.groupby(by=['OrderID'])['ConfCnt'].agg([\"sum\"]).reset_index()\n",
    "train_dop5 = train.groupby(by=['OrderID'])['OrderID'].agg([\"count\"]).reset_index()\n",
    "\n",
    "#test_dop1 = test.groupby(by=['OrderID', 'GroupID'])['OrderCnt'].agg([\"sum\"]).unstack(level=-1).reset_index().fillna(0)\n",
    "#test_dop2 = test.groupby(by=['OrderID', 'GroupID'])['ConfCnt'].agg([\"sum\"]).unstack(level=-1).reset_index().fillna(0)\n",
    "test_dop3 = test.groupby(by=['OrderID'])['OrderCnt'].agg([\"sum\"]).reset_index()\n",
    "test_dop4 = test.groupby(by=['OrderID'])['ConfCnt'].agg([\"sum\"]).reset_index()\n",
    "test_dop5 = test.groupby(by=['OrderID'])['OrderID'].agg([\"count\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.groupby(by=['OrderID', 'Interval', 'Date', 'OrderDate', 'ClientID', 'ChannelID', 'Cluster', 'DeliveryType', 'prepay', 'count_edit'])['Delta'].agg([\"mean\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.groupby(by=['OrderID', 'Interval', 'Date', 'OrderDate', 'ClientID', 'ChannelID', 'Cluster', 'DeliveryType', 'prepay', 'count_edit'])['prepay'].agg([\"count\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Delta'] = train['mean']\n",
    "train = train.drop(['mean'], axis=1)\n",
    "test = test.drop(['count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train.merge(train_dop1, on=['OrderID'], how='left')\n",
    "#train = train.merge(train_dop2, on=['OrderID'], how='left')\n",
    "train = train.merge(train_dop3, on=['OrderID'], how='left')\n",
    "train = train.merge(train_dop4, on=['OrderID'], how='left')\n",
    "train = train.merge(train_dop5, on=['OrderID'], how='left')\n",
    "\n",
    "#test = test.merge(test_dop1, on=['OrderID'], how='left')\n",
    "#test = test.merge(test_dop2, on=['OrderID'], how='left')\n",
    "test = test.merge(test_dop3, on=['OrderID'], how='left')\n",
    "test = test.merge(test_dop4, on=['OrderID'], how='left')\n",
    "test = test.merge(test_dop5, on=['OrderID'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cnt_delta'] = train.sum_y/train.sum_x\n",
    "test['cnt_delta'] = test.sum_y/test.sum_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort_values(by=['ClientID', 'OrderDate', 'OrderID'])\n",
    "train['ttt'] = train[['ClientID', 'OrderDate']].duplicated(keep='last')\n",
    "train['ttt'] = train.ttt.apply(lambda x: 1 if (x == True) else 0)\n",
    "train = train.sort_values(by=['OrderID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.sort_values(by=['ClientID', 'OrderDate', 'OrderID'])\n",
    "test['ttt'] = test[['ClientID', 'OrderDate']].duplicated(keep='last')\n",
    "test['ttt'] = test.ttt.apply(lambda x: 1 if (x == True) else 0)\n",
    "test = test.sort_values(by=['OrderID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "#для обучения нам не нужны безотказные заказы\n",
    "train = train[train.Delta != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#доп.признаки (не все они понадобятся в итоге)\n",
    "train['DeliveryType_int'] = train.DeliveryType.apply(lambda x: 0 if (x == 'Îáû÷íàÿ äîñòàâêà') else 1)\n",
    "train['Date_dd'] = train.Date.dt.day\n",
    "train['Date_mm'] = train.Date.dt.month\n",
    "train['Date_y'] = train.Date.dt.year\n",
    "train['Date_weekday'] = train.Date.dt.weekday\n",
    "train['Date_dy'] = train.Date.dt.dayofyear\n",
    "train['OrderDate_dd'] = train.OrderDate.dt.day\n",
    "train['OrderDate_mm'] = train.OrderDate.dt.month\n",
    "train['OrderDate_y'] = train.OrderDate.dt.year\n",
    "train['OrderDate_weekdate'] = train.OrderDate.dt.weekday\n",
    "train['OrderDate_dy'] = train.OrderDate.dt.dayofyear\n",
    "train['delta_days'] = train.Date - train.OrderDate\n",
    "train['delta_days'] = (24.0*train['delta_days'].astype(np.int64)/86400000000000).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#аналогичные доп.признаки для test\n",
    "test['DeliveryType_int'] = test.DeliveryType.apply(lambda x: 0 if (x == 'Îáû÷íàÿ äîñòàâêà') else 1)\n",
    "test['Date_dd'] = test.Date.dt.day\n",
    "test['Date_mm'] = test.Date.dt.month\n",
    "test['Date_y'] = test.Date.dt.year\n",
    "test['Date_weekday'] = test.Date.dt.weekday\n",
    "test['Date_dy'] = test.Date.dt.dayofyear\n",
    "test['OrderDate_dd'] = test.OrderDate.dt.day\n",
    "test['OrderDate_mm'] = test.OrderDate.dt.month\n",
    "test['OrderDate_y'] = test.OrderDate.dt.year\n",
    "test['OrderDate_weekdate'] = test.OrderDate.dt.weekday\n",
    "test['OrderDate_dy'] = test.OrderDate.dt.dayofyear\n",
    "test['delta_days'] = test.Date - test.OrderDate\n",
    "test['delta_days'] = (24.0*test['delta_days'].astype(np.int64)/86400000000000).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "#заэнкодим временные интервалы доставки (много почему-то не дают, но все же)\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(list(set(pd.unique(test.Interval)) | set(pd.unique(train.Interval))))\n",
    "train['Interval_int'] = le.transform(train['Interval'].values) \n",
    "test['Interval_int'] = le.transform(test['Interval'].values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "#уберем предновогодние выбросы <180 (в тесте нет предновогоднего периода)\n",
    "train = train[train.Delta < 180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаем массив признаков, которые не пойдут в модель\n",
    "KILL_COLS = [\n",
    "    'Interval', 'sum_x', \n",
    "    'Date', \n",
    "    'OrderDate', \n",
    "    'DeliveryType', \n",
    "    'Cluster', \n",
    "    'Delta', \n",
    "    'Date_y', \n",
    "    'OrderDate_y',\n",
    "    'Date_dy',\n",
    "    'OrderDate_dy'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "#такой же массив для тестового набора\n",
    "KILL_COLS_TEST = [\n",
    "    'Interval', 'sum_x',\n",
    "    'Date', \n",
    "    'OrderDate', \n",
    "    'DeliveryType', \n",
    "    'Cluster', \n",
    "    'Date_y', \n",
    "    'OrderDate_y',\n",
    "    'Date_dy',\n",
    "    'OrderDate_dy'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_test_split (отладочный блок)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сделаем примитивную разбивку на train/test без шаффла\n",
    "train_part, validation = train_test_split(train, test_size=0.33, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.2650601679974\n"
     ]
    }
   ],
   "source": [
    "#13.728298224967453\n",
    "lgb = lightgbm.LGBMRegressor(random_state=0)\n",
    "lgb.fit(train_part.drop(KILL_COLS, axis = 1).values, train_part['Delta'].values)\n",
    "\n",
    "pred_lgb = lgb.predict(validation.drop(KILL_COLS, axis = 1).values)\n",
    "print(math.sqrt(mean_squared_error(validation['Delta'].values, pred_lgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.746025704242703\n"
     ]
    }
   ],
   "source": [
    "#13.767881025653487\n",
    "GBoost = GradientBoostingRegressor(n_estimators=320, learning_rate=0.04,\n",
    "                                   max_depth=5, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, loss='huber', random_state=1)\n",
    "GBoost.fit(train_part.drop(KILL_COLS, axis = 1).values, train_part['Delta'].values)\n",
    "pred_GBoost = GBoost.predict(validation.drop(KILL_COLS, axis = 1).values)\n",
    "print(math.sqrt(mean_squared_error(validation['Delta'].values, pred_GBoost)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([247, 462,  22,  12,  98, 239,  34, 226,  27, 171,  17, 124,  82,\n",
       "        75, 108,  79,  87, 510, 380], dtype=int32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model (LGBM + GradientBoostingRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "#устраним последствия деления на ноль (деление количества подтвержденных позиций на колчиество заказанных - см.выше в блоке подготовки доп.признаков)\n",
    "test=test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = lightgbm.LGBMRegressor(random_state=0, n_estimators=110)\n",
    "lgb.fit(train.drop(KILL_COLS, axis=1).values, train['Delta'].values)\n",
    "#lgb.fit(train.drop(KILL_COLS, axis=1).values, (train[[\"Delta\"]].values - train[\"Delta\"].mean())/(train[\"Delta\"].std()))\n",
    "pred_lgb = lgb.predict(test.drop(KILL_COLS_TEST, axis=1).values)\n",
    "#pred_lgb = lgb.predict(test.drop(KILL_COLS_TEST, axis=1).values)*train[\"Delta\"].std() + train[\"Delta\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([test.OrderID, pd.DataFrame(pred_lgb, columns=['Score'])], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=330, learning_rate=0.04,\n",
    "                                   max_depth=5, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, loss='huber', random_state=1)\n",
    "GBoost.fit(train.drop(KILL_COLS, axis=1).values, train['Delta'].values)\n",
    "pred_GBoost = GBoost.predict(test.drop(KILL_COLS_TEST, axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([test.OrderID, pd.DataFrame(pred_GBoost, columns=['Score'])], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "#для смешивания результатов \n",
    "temp = pd.concat([test.OrderID, pd.DataFrame((pred_GBoost+pred_lgb)/2.0, columns=['Score'])], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерируем файл ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "otvet = pd.read_csv('empty2.csv')\n",
    "otvet = otvet.drop([' Score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['ID'] = temp.OrderID\n",
    "temp[' Score'] = temp.Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "otvet=otvet.merge(temp, on=['ID'], how='left').drop(['Score', 'OrderID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "otvet.to_csv('Submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
